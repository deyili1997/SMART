{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d9a5b37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "%store -r time_window\n",
    "%store -r lab_feature_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8eac94c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lab_feature_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f738398",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_processors = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb2bbaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"/blue/yonghui.wu/lideyi/Personalization_Methodology/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf704b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data overlap rate (entire dataset)\n",
    "SCR_overlap = np.load('/blue/yonghui.wu/lideyi/Personalization_Methodology/SCR_overlap.npy')\n",
    "LAB_overlap = np.load('/blue/yonghui.wu/lideyi/Personalization_Methodology/lab_overlap.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25394ab3-e1c8-4841-8c8a-c030bc542feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(SCR_overlap.shape[0] == LAB_overlap.shape[0])\n",
    "assert(~np.isnan(SCR_overlap).any())\n",
    "assert(~np.isnan(LAB_overlap).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72907502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# no need to shuffle again since we have done it.\n",
    "%store -r train_len\n",
    "%store -r test_len\n",
    "\n",
    "data_train = dataset.iloc[:train_len, :].copy(deep = True)\n",
    "data_test = dataset.iloc[train_len:, :].copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1204a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert((len(data_train) + len(data_test)) == len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027db2b2-17fa-47f4-87bd-0a34fe430560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset by train and test\n",
    "data_train = (data_train - data_train.min(skipna=True)) / \\\n",
    "(data_train.max(skipna=True) - data_train.min(skipna=True))\n",
    "\n",
    "data_test = (data_test - data_test.min(skipna=True)) / \\\n",
    "(data_test.max(skipna=True) - data_test.min(skipna=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1686c03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# consequently, we will only use the upper-left block of the overlap rate mtx for just val set\n",
    "SCR_overlap_train = SCR_overlap[:len(data_train), :len(data_train)]\n",
    "LAB_overlap_train = LAB_overlap[:len(data_train), :len(data_train)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4932b8",
   "metadata": {},
   "source": [
    "# Compute SCr Similarity "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5319fa32",
   "metadata": {},
   "source": [
    "Methods: DTW-AROW on raw, linear interpolation + Euclidean distance, cosine similarity, Manhattan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2469a890",
   "metadata": {},
   "source": [
    "1. DTW-AROW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be3c2038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to compute similarity mtx on SCR, we still need to compute the global\n",
    "# SCR similarity mtx (so that we can use well-written functions)\n",
    "# DTW-AROW\n",
    "import sys\n",
    "sys.path.append('/home/lideyi/AKI_Personalization_Methodology/DTW_with_missing_values')\n",
    "import dtw_missing.dtw_missing as dtw_m\n",
    "from Z_Helping_Functions import translate_dist_mtx_to_simi, fast_argsort, slow_argsort, min_max_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e28d451",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get SCR measurements for val(i.e. both train and dev)\n",
    "SCR = dataset.loc[:, time_window]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66f26ae-4c8c-4a02-977d-b26c3d72a486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_distance_matrix(df, num_processes, metric):\n",
    "    pool = Pool(num_processes)\n",
    "    total = len(df)\n",
    "\n",
    "    results = list(tqdm(pool.imap(calculate_overlap, \n",
    "                                  [(i, df, metric) for i in range(total - 1)]), \n",
    "                            total=total - 1))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return create_distance_matrix(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe907af8-4696-448c-9102-d37a6560ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overlap(args):\n",
    "    index, df, metric = args\n",
    "    return [metric(df.iloc[index], df.iloc[j]) for j in range(index + 1, len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c391465-5b6a-4e50-b9da-2cf57c0c6cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distance_matrix(distance_list):\n",
    "    n = len(distance_list[0]) + 1\n",
    "\n",
    "    matrix = np.zeros((n, n))\n",
    "\n",
    "    for i in range(n-1):\n",
    "        matrix[i, i+1:i+1+len(distance_list[i])] = distance_list[i]\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            matrix[j, i] = matrix[i, j]\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85df33bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_DTW_distance(u, v):\n",
    "    u = np.array(u)\n",
    "    v = np.array(v)\n",
    "    d = dtw_m.warping_paths(u, v)[0]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a3f9ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SCR_DTW_dist = parallel_distance_matrix(SCR, num_processors, get_DTW_distance)\n",
    "# np.save('/blue/yonghui.wu/lideyi/Personalization_Methodology/SCR_DTW_dist_imput2.npy', SCR_DTW_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f553edcb-aeac-462c-a7d2-242c2fc32e63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_DTW_dist = np.load('/blue/yonghui.wu/lideyi/Personalization_Methodology/SCR_DTW_dist_imput2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e92471c-4dde-4748-ae0e-6df8b58dc0b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transfrom distance mtx to similarity score mtx by min-max normalization\n",
    "SCR_DTW_simi = translate_dist_mtx_to_simi(SCR_DTW_dist)\n",
    "# transform similarity score mtx to idx matrix by most similar rank highest\n",
    "SCR_DTW_idx = fast_argsort(SCR_DTW_simi, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7038d0-9069-4b43-9fa3-1a2a712b0aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_DTW_dist_train = SCR_DTW_dist[:len(data_train), :len(data_train)]\n",
    "SCR_DTW_simi_train = translate_dist_mtx_to_simi(SCR_DTW_dist_train)\n",
    "SCR_DTW_idx_train = fast_argsort(SCR_DTW_simi_train, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fd3619-c691-4f32-8765-a041f4705604",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert(~np.isnan(SCR_DTW_simi).any())\n",
    "assert(~np.isnan(SCR_DTW_idx).any())\n",
    "assert(~np.isnan(SCR_DTW_simi_train).any())\n",
    "assert(~np.isnan(SCR_DTW_idx_train).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3ae6a0",
   "metadata": {},
   "source": [
    "2. Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b8c5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Euclidean distance and following methods do not support missing values.\n",
    "# we need use interpolation to fill in missing values\n",
    "SCR_ip = SCR.interpolate(method='linear', axis = 1)\n",
    "SCR_ip = SCR_ip.fillna(method='bfill', axis = 1)\n",
    "SCR_ip = SCR_ip.fillna(method='ffill', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ebf2a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086bc0f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Euc_dist = pairwise_distances(SCR_ip, metric='euclidean', n_jobs=-1)\n",
    "SCR_Euc_simi = translate_dist_mtx_to_simi(SCR_Euc_dist)\n",
    "SCR_Euc_idx = fast_argsort(SCR_Euc_simi, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b457d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Euc_dist_train = SCR_Euc_dist[:len(data_train), :len(data_train)]\n",
    "SCR_Euc_simi_train = translate_dist_mtx_to_simi(SCR_Euc_dist_train)\n",
    "SCR_Euc_idx_train = fast_argsort(SCR_Euc_simi_train, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645642ef-a1fd-47cc-97f0-edca03a84f0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert(~np.isnan(SCR_Euc_simi).any())\n",
    "assert(~np.isnan(SCR_Euc_idx).any())\n",
    "assert(~np.isnan(SCR_Euc_simi_train).any())\n",
    "assert(~np.isnan(SCR_Euc_idx_train).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a41fe5",
   "metadata": {},
   "source": [
    "3. Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97ef362",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Cos_dist = pairwise_distances(SCR_ip, metric='cosine', n_jobs=-1)\n",
    "SCR_Cos_simi = translate_dist_mtx_to_simi(SCR_Cos_dist)\n",
    "SCR_Cos_idx = fast_argsort(SCR_Cos_simi, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fd5c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Cos_dist_train = SCR_Cos_dist[:len(data_train), :len(data_train)]\n",
    "SCR_Cos_simi_train = translate_dist_mtx_to_simi(SCR_Cos_dist_train)\n",
    "SCR_Cos_idx_train = fast_argsort(SCR_Cos_simi_train, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc736c6d-beb8-40bb-8723-5b300209a9fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert(~np.isnan(SCR_Cos_simi).any())\n",
    "assert(~np.isnan(SCR_Cos_idx).any())\n",
    "assert(~np.isnan(SCR_Cos_simi_train).any())\n",
    "assert(~np.isnan(SCR_Cos_idx_train).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982bc5c3",
   "metadata": {},
   "source": [
    "4. Manhattan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2f3d56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Manh_dist = pairwise_distances(SCR_ip, metric='manhattan', n_jobs=-1)\n",
    "SCR_Manh_simi = translate_dist_mtx_to_simi(SCR_Manh_dist)\n",
    "SCR_Manh_idx = fast_argsort(SCR_Manh_simi, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd539707",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Manh_dist_train = SCR_Manh_dist[:len(data_train), :len(data_train)]\n",
    "SCR_Manh_simi_train = translate_dist_mtx_to_simi(SCR_Manh_dist_train)\n",
    "SCR_Manh_idx_train = fast_argsort(SCR_Manh_simi_train, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d589cfd7-ffe7-4080-8df2-8a33bc3fcbcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert(~np.isnan(SCR_Cos_simi).any())\n",
    "assert(~np.isnan(SCR_Cos_idx).any())\n",
    "assert(~np.isnan(SCR_Cos_simi_train).any())\n",
    "assert(~np.isnan(SCR_Cos_idx_train).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d33246b",
   "metadata": {},
   "source": [
    "# Compute Lab Similarity "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638dc29f",
   "metadata": {},
   "source": [
    "Replace missing value by MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e8b7b2-f914-467a-a5b3-fed8114b9f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1b2585",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LAB_train = data_train.loc[:, lab_feature_space]\n",
    "LAB_test = data_test.loc[:, lab_feature_space]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd74848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imputer = IterativeImputer(missing_values=np.nan, \n",
    "                           max_iter=10, random_state=42)\n",
    "# should only fit on train data in case for data leakage\n",
    "imputer.fit(LAB_train)\n",
    "\n",
    "LAB_train_ip = imputer.transform(LAB_train)\n",
    "LAB_test_ip = imputer.transform(LAB_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2ec8c1-2219-48b5-90a2-cde6173b5c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the entire lab feature space with imputated value\n",
    "LAB_train.loc[:, :] = LAB_train_ip\n",
    "LAB_test.loc[:, :] = LAB_test_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5b4a5c-8cbf-4d34-b5ee-708c606c6ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we concate train and test back together to facilitate computing\n",
    "# but still metric is learned from train data\n",
    "LAB_ip = pd.concat([LAB_train, LAB_test], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdda5b7",
   "metadata": {},
   "source": [
    "1. Use Euclidean Distance to measure Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daf8bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LAB_Euc_dist = pairwise_distances(LAB_ip, metric='euclidean', n_jobs=-1)\n",
    "LAB_Euc_simi = translate_dist_mtx_to_simi(LAB_Euc_dist)\n",
    "LAB_Euc_idx = fast_argsort(LAB_Euc_simi, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f744b3e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LAB_Euc_dist_train = LAB_Euc_dist[:len(data_train), :len(data_train)]\n",
    "LAB_Euc_simi_train = translate_dist_mtx_to_simi(LAB_Euc_dist_train)\n",
    "LAB_Euc_idx_train = fast_argsort(LAB_Euc_simi_train, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28f7fc6-c533-4710-a465-ed04f9cedbaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert(~np.isnan(LAB_Euc_simi).any())\n",
    "assert(~np.isnan(LAB_Euc_idx).any())\n",
    "assert(~np.isnan(LAB_Euc_simi_train).any())\n",
    "assert(~np.isnan(LAB_Euc_idx_train).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e130502-0a69-4f4a-83e6-e25b19728f91",
   "metadata": {},
   "source": [
    "2. Use Cosine Distance to measure Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58e3eef-6716-4357-90de-729c99995e3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LAB_Cos_dist = pairwise_distances(LAB_ip, metric='cosine', n_jobs=-1)\n",
    "LAB_Cos_simi = translate_dist_mtx_to_simi(LAB_Cos_dist)\n",
    "LAB_Cos_idx = fast_argsort(LAB_Cos_simi, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b715c5a-815c-4a0d-aa07-7dc8f839ae05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LAB_Cos_dist_train = LAB_Cos_dist[:len(data_train), :len(data_train)]\n",
    "LAB_Cos_simi_train = translate_dist_mtx_to_simi(LAB_Cos_dist_train)\n",
    "LAB_Cos_idx_train = fast_argsort(LAB_Cos_simi_train, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d345c08a-b46c-4390-85ba-3066939959ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert(~np.isnan(LAB_Cos_simi).any())\n",
    "assert(~np.isnan(LAB_Cos_idx).any())\n",
    "assert(~np.isnan(LAB_Cos_simi_train).any())\n",
    "assert(~np.isnan(LAB_Cos_idx_train).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c0155c-b9c7-4a31-857e-e67d111a3aa2",
   "metadata": {},
   "source": [
    "3. Use Manhattan Distance to measure Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55de9ce5-40e1-4281-bcf4-92860f62da78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LAB_Manh_dist = pairwise_distances(LAB_ip, metric='manhattan', n_jobs=-1)\n",
    "LAB_Manh_simi = translate_dist_mtx_to_simi(LAB_Manh_dist)\n",
    "LAB_Manh_idx = fast_argsort(LAB_Manh_simi, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b49e97-a893-4d82-bc9a-c3d40117d409",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LAB_Manh_dist_train = LAB_Manh_dist[:len(data_train), :len(data_train)]\n",
    "LAB_Manh_simi_train = translate_dist_mtx_to_simi(LAB_Manh_dist_train)\n",
    "LAB_Manh_idx_train = fast_argsort(LAB_Manh_simi_train, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10457f21-35fd-4aa5-ae88-375ddf551ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert(~np.isnan(LAB_Manh_simi).any())\n",
    "assert(~np.isnan(LAB_Manh_idx).any())\n",
    "assert(~np.isnan(LAB_Manh_simi_train).any())\n",
    "assert(~np.isnan(LAB_Manh_idx_train).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3396f0",
   "metadata": {},
   "source": [
    "# Weighting Each Simi Mtx Computed Above by Overlap Rates and Re-estimate Idx Mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2d44f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weighted_by_overlap_mtx(overlap_mtx, simi_mtx, num_processors):\n",
    "    weighted_simi = overlap_mtx * simi_mtx\n",
    "    weighted_idx = fast_argsort(weighted_simi, num_processors)\n",
    "    return weighted_simi, weighted_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc723ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# val\n",
    "# for all SCR similarity mtx\n",
    "SCR_DTW_simi_w, SCR_DTW_idx_w = weighted_by_overlap_mtx(SCR_overlap, SCR_DTW_simi, num_processors)\n",
    "SCR_Euc_simi_w, SCR_Euc_idx_w = weighted_by_overlap_mtx(SCR_overlap, SCR_Euc_simi, num_processors)\n",
    "SCR_Cos_simi_w, SCR_Cos_idx_w = weighted_by_overlap_mtx(SCR_overlap, SCR_Cos_simi, num_processors)\n",
    "SCR_Manh_simi_w, SCR_Manh_idx_w = weighted_by_overlap_mtx(SCR_overlap, SCR_Manh_simi, num_processors)\n",
    "\n",
    "# for all LAB similarity mtx\n",
    "LAB_Euc_simi_w, LAB_Euc_idx_w = weighted_by_overlap_mtx(LAB_overlap, LAB_Euc_simi, num_processors)\n",
    "LAB_Cos_simi_w, LAB_Cos_idx_w = weighted_by_overlap_mtx(LAB_overlap, LAB_Cos_simi, num_processors)\n",
    "LAB_Manh_simi_w, LAB_Manh_idx_w = weighted_by_overlap_mtx(LAB_overlap, LAB_Manh_simi, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f2421c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train\n",
    "# for all SCR similarity mtx\n",
    "SCR_DTW_simi_w_train, SCR_DTW_idx_w_train = weighted_by_overlap_mtx(SCR_overlap_train, SCR_DTW_simi_train, num_processors)\n",
    "SCR_Euc_simi_w_train, SCR_Euc_idx_w_train = weighted_by_overlap_mtx(SCR_overlap_train, SCR_Euc_simi_train, num_processors)\n",
    "SCR_Cos_simi_w_train, SCR_Cos_idx_w_train = weighted_by_overlap_mtx(SCR_overlap_train, SCR_Cos_simi_train, num_processors)\n",
    "SCR_Manh_simi_w_train, SCR_Manh_idx_w_train = weighted_by_overlap_mtx(SCR_overlap_train, SCR_Manh_simi_train, num_processors)\n",
    "\n",
    "# for all LAB similarity mtx\n",
    "LAB_Euc_simi_w_train, LAB_Euc_idx_w_train = weighted_by_overlap_mtx(LAB_overlap_train, LAB_Euc_simi_train, num_processors)\n",
    "LAB_Cos_simi_w_train, LAB_Cos_idx_w_train = weighted_by_overlap_mtx(LAB_overlap_train, LAB_Cos_simi_train, num_processors)\n",
    "LAB_Manh_simi_w_train, LAB_Manh_idx_w_train = weighted_by_overlap_mtx(LAB_overlap_train, LAB_Manh_simi_train, num_processors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb8b020",
   "metadata": {},
   "source": [
    "# Summary of Similarity Idx Matrices, Sanity Check and Organize them into Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4a14ea",
   "metadata": {},
   "source": [
    "The similarity idx matrix is for the entire data(train + test). We only need the neareast neighbors in training data for each test data point. Thus we organize them into dictionaries. Keys are the index of each test data point and values are lists of the indicies of nearest training data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f442348-e4af-4beb-9910-cded47bc19e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab89c9aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get idx to process dicts\n",
    "train_idx = np.array(data_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e83251c-7e49-4b70-89a6-c14ca1abf42d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate simi_dict for one-vs-all val\n",
    "def process_similarity_arr_for_train(train_idx, y_train, simi_mtx, idx_mtx):\n",
    "    neighbor_idx = remove_elements_equal_to_row_index(idx_mtx)\n",
    "    \n",
    "    neighbor_simi = extract_elements_based_on_indices(neighbor_idx, simi_mtx)\n",
    "    \n",
    "    y_train_arr = np.tile(y_train, (neighbor_idx.shape[0], 1))\n",
    "    \n",
    "    neighbor_y = extract_elements_based_on_indices(neighbor_idx, y_train_arr)\n",
    "    \n",
    "    assert(neighbor_simi.shape[1] == neighbor_y.shape[1])\n",
    "    \n",
    "    return neighbor_simi, neighbor_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2123c94b-9f9e-4db9-9947-3b21712a9ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_elements_based_on_indices(idx_mtx, base_mtx):\n",
    "    # Convert the input matrices to NumPy arrays for easier manipulation\n",
    "    \n",
    "    if np.any(idx_mtx >= base_mtx.shape[1]) or np.any(idx_mtx < 0):\n",
    "        raise ValueError(\"Matrix A contains indices that are out of bounds for Matrix B\")\n",
    "    \n",
    "    # Use advanced indexing to select the elements from matrix_b\n",
    "    row_indices = np.arange(idx_mtx.shape[0])[:, None]  # Create an array of row indices\n",
    "    result_matrix = base_mtx[row_indices, idx_mtx]  # Use the row indices and matrix_a for advanced indexing\n",
    "    \n",
    "    return result_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a61e9d3-b213-4afc-b718-936224a54490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_elements_equal_to_row_index(matrix):\n",
    "    # Convert the input matrix to a NumPy array for easier manipulation\n",
    "    matrix = np.array(matrix)\n",
    "    \n",
    "    # Create a list to hold the new rows\n",
    "    new_matrix = []\n",
    "    \n",
    "    # Iterate through each row in the matrix\n",
    "    for row_index in range(matrix.shape[0]):\n",
    "        # Get the current row\n",
    "        row = matrix[row_index]\n",
    "        # Create a new row excluding the element equal to the row index\n",
    "        new_row = row[row != row_index]\n",
    "        # Append the new row to the new_matrix list\n",
    "        new_matrix.append(new_row)\n",
    "    \n",
    "    # Convert the list of rows back to a NumPy array\n",
    "    new_matrix = np.array(new_matrix)\n",
    "    \n",
    "    return new_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be28337-e0d6-4f2f-91df-79b664faeb7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = np.array(data_train[\"AKI_LABEL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd2146d-08f8-4259-8714-63f92985d918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_DTW_simi_train_clean, SCR_DTW_y_train_clean = process_similarity_arr_for_train(train_idx, y_train, SCR_DTW_simi_train, SCR_DTW_idx_train)\n",
    "SCR_DTW_simi_w_train_clean, SCR_DTW_y_w_train_clean = process_similarity_arr_for_train(train_idx, y_train, SCR_DTW_simi_w_train, SCR_DTW_idx_w_train)\n",
    "\n",
    "SCR_Euc_simi_train_clean, SCR_Euc_y_train_clean = process_similarity_arr_for_train(train_idx, y_train, SCR_Euc_simi_train, SCR_Euc_idx_train)\n",
    "SCR_Euc_simi_w_train_clean, SCR_Euc_y_w_train_clean = process_similarity_arr_for_train(train_idx, y_train, SCR_Euc_simi_w_train, SCR_Euc_idx_w_train)\n",
    "\n",
    "SCR_Cos_simi_train_clean, SCR_Cos_y_train_clean = process_similarity_arr_for_train(train_idx, y_train, SCR_Cos_simi_train, SCR_Cos_idx_train)\n",
    "SCR_Cos_simi_w_train_clean, SCR_Cos_y_w_train_clean = process_similarity_arr_for_train(train_idx, y_train, SCR_Cos_simi_w_train, SCR_Cos_idx_w_train)\n",
    "\n",
    "SCR_Manh_simi_train_clean, SCR_Manh_y_train_clean = process_similarity_arr_for_train(train_idx, y_train, SCR_Manh_simi_train, SCR_Manh_idx_train)\n",
    "SCR_Manh_simi_w_train_clean, SCR_Manh_y_w_train_clean = process_similarity_arr_for_train(train_idx, y_train, SCR_Manh_simi_w_train, SCR_Manh_idx_w_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d5588c-c4c1-4a8c-9341-9855dd93f730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LAB_Euc_simi_train_clean, LAB_Euc_y_train_clean = process_similarity_arr_for_train(train_idx, y_train, LAB_Euc_simi_train, LAB_Euc_idx_train)\n",
    "LAB_Euc_simi_w_train_clean, LAB_Euc_y_w_train_clean = process_similarity_arr_for_train(train_idx, y_train, LAB_Euc_simi_w_train, LAB_Euc_idx_w_train)\n",
    "\n",
    "LAB_Cos_simi_train_clean, LAB_Cos_y_train_clean = process_similarity_arr_for_train(train_idx, y_train, LAB_Cos_simi_train, LAB_Cos_idx_train)\n",
    "LAB_Cos_simi_w_train_clean, LAB_Cos_y_w_train_clean = process_similarity_arr_for_train(train_idx, y_train, LAB_Cos_simi_w_train, LAB_Cos_idx_w_train)\n",
    "\n",
    "LAB_Manh_simi_train_clean, LAB_Manh_y_train_clean = process_similarity_arr_for_train(train_idx, y_train, LAB_Manh_simi_train, LAB_Manh_idx_train)\n",
    "LAB_Manh_simi_w_train_clean, LAB_Manh_y_w_train_clean = process_similarity_arr_for_train(train_idx, y_train, LAB_Manh_simi_w_train, LAB_Manh_idx_w_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb91aa8",
   "metadata": {},
   "source": [
    "# Define Global Parameters  and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dad6d77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# neighborhood size, \n",
    "k_sizes = [i for i in range(1, 200, 4)]\n",
    "%store k_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62674a17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#return AUROC and AUPRC at a certain size k\n",
    "def KNN(simi_dict, k, y_test, use_weighted_voting):\n",
    "    assert(len(y_test) == simi_dict[\"label\"].shape[0])\n",
    "    \n",
    "    y_probs = []\n",
    "    y_preds = []\n",
    "    \n",
    "    for i in range(len(y_test)):\n",
    "        k_labels = simi_dict[\"label\"][i, :k]\n",
    "        k_scores = simi_dict[\"score\"][i, :k]\n",
    "\n",
    "        \n",
    "        if not use_weighted_voting:\n",
    "            y_prob = np.sum(k_labels) / len(k_labels)\n",
    "        else:\n",
    "            y_prob = weighted_voting(k_labels, k_scores)\n",
    "            \n",
    "        y_probs.append(y_prob)\n",
    "        \n",
    "        if y_prob >= 0.5:\n",
    "            y_preds.append(1)\n",
    "        else:\n",
    "            y_preds.append(0)\n",
    "    \n",
    "    assert(len(y_probs) == len(y_test))\n",
    "    assert(not np.isnan(np.array(y_probs)).any())\n",
    "    \n",
    "    #AUPRC and AUROC\n",
    "    AUPRC = average_precision_score(y_test, y_probs)\n",
    "    AUROC = roc_auc_score(y_test, y_probs)\n",
    "    f1 = f1_score(y_test, y_preds)\n",
    "    return AUPRC, AUROC, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f63549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we also want to test whether weighted KNN can enhance the performance\n",
    "def weighted_voting(k_labels, k_scores):\n",
    "    total_weight = np.sum(k_scores)\n",
    "    \n",
    "    #address the deno is 0\n",
    "    if total_weight == 0:\n",
    "        return 0\n",
    "    \n",
    "    weighted_ones = np.sum(np.array(k_labels) * np.array(k_scores))\n",
    "\n",
    "    assert(weighted_ones <= total_weight)\n",
    "    weighted_probability = weighted_ones / total_weight\n",
    "\n",
    "    return weighted_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5230e451",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# main function: return a dict, key is name and performance, value of \"name\" is a list of length len(k_sizes)\n",
    "# record the best distance measure for this k under the condition of weither overlap weighting or weignted KNN voting\n",
    "# performance is AUPRC\n",
    "def compare_feature_repr(simi_dict_collection, y_test, \n",
    "                         k_sizes, use_weighted_voting = False):\n",
    "    #simi_dict_collection is a dict and of structure: {Method name: simi_dict}\n",
    "    \n",
    "    best_method_each_k = dict()\n",
    "    best_method_each_k[\"name\"] = []\n",
    "    best_method_each_k[\"performance\"] = []\n",
    "    \n",
    "    for k in tqdm(k_sizes):\n",
    "        \n",
    "        best_method_name = ''\n",
    "        best_method_performance = 0\n",
    "        \n",
    "        for name, simi_dict in simi_dict_collection.items():\n",
    "            AUPRC, AUROC, f1 = KNN(simi_dict, k, y_test, use_weighted_voting)\n",
    "            \n",
    "            focus_metirc = AUPRC\n",
    "            \n",
    "            # if better AUPRC, update\n",
    "            if focus_metirc > best_method_performance:\n",
    "                best_method_name = name\n",
    "                best_method_performance = focus_metirc\n",
    "                \n",
    "        best_method_each_k[\"name\"].append(best_method_name)\n",
    "        best_method_each_k[\"performance\"].append(best_method_performance)\n",
    "    \n",
    "    return best_method_each_k    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119a4e7d-132f-485b-ba7b-f61732f9bdc0",
   "metadata": {},
   "source": [
    "# Search Best Distance Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9213c930",
   "metadata": {},
   "source": [
    "Fill in the Record dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a458687e-6a3e-4bc1-a0d3-cb2912f3d2c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a table to track all performance\n",
    "# OW is overlap rate weighting, WV is weighted KNN voting\n",
    "grid_search_table = \\\n",
    "pd.DataFrame('', index = k_sizes, \n",
    "             columns = [\"SCR Vanilla\", \"LAB Vanilla\", \"SCR OW\", \"LAB OW\"])\n",
    "grid_search_table.index.name = \"k\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198dfc6c-4702-4d99-b751-bd29150c2519",
   "metadata": {},
   "source": [
    "SCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10e729e-af35-4d3d-bf44-a6b81ae42407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_simi_dict_collection = {\n",
    "    \"DTW\": {\"score\": SCR_DTW_simi_train_clean, \"label\":SCR_DTW_y_train_clean},\n",
    "    \"Euc\": {\"score\": SCR_Euc_simi_train_clean, \"label\":SCR_Euc_y_train_clean},\n",
    "    \"Cos\": {\"score\": SCR_Cos_simi_train_clean, \"label\":SCR_Cos_y_train_clean},\n",
    "    \"Manh\": {\"score\": SCR_Manh_simi_train_clean, \"label\":SCR_Manh_y_train_clean},\n",
    "}\n",
    "\n",
    "# dict of dicts of overlap rate weighted similarity\n",
    "SCR_simi_w_dict_collection = {\n",
    "    \"DTW\": {\"score\": SCR_DTW_simi_w_train_clean, \"label\":SCR_DTW_y_w_train_clean},\n",
    "    \"Euc\": {\"score\": SCR_Euc_simi_w_train_clean, \"label\":SCR_Euc_y_w_train_clean},\n",
    "    \"Cos\": {\"score\": SCR_Cos_simi_w_train_clean, \"label\":SCR_Cos_y_w_train_clean},\n",
    "    \"Manh\": {\"score\": SCR_Manh_simi_w_train_clean, \"label\":SCR_Manh_y_w_train_clean},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b68c651-ec4c-4af7-8803-86dc0227e8c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SCR no overlap weighting no weighted voting\n",
    "# vv is vanilla voting\n",
    "# no is not overlap weighting\n",
    "SCR_no_vv = compare_feature_repr(SCR_simi_dict_collection, y_train, k_sizes, use_weighted_voting = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af7c08a-0f4b-4d3f-880f-6f473d6fff6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SCR yes overlap weighting no weighted voting\n",
    "# w is overlap weighting\n",
    "SCR_ow_vv = compare_feature_repr(SCR_simi_w_dict_collection, y_train, k_sizes, use_weighted_voting = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae91567-e8f5-4325-a1b9-eb1371b44346",
   "metadata": {},
   "source": [
    "LAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3444977d-dca6-494c-ad74-c18b8de4707b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LAB_simi_dict_collection = {\n",
    "    \"Euc\": {\"score\": LAB_Euc_simi_train_clean, \"label\":LAB_Euc_y_train_clean},\n",
    "    \"Cos\": {\"score\": LAB_Cos_simi_train_clean, \"label\":LAB_Cos_y_train_clean},\n",
    "    \"Manh\": {\"score\": LAB_Manh_simi_train_clean, \"label\":LAB_Manh_y_train_clean},\n",
    "}\n",
    "\n",
    "# dict of dicts of overlap rate weighted similarity\n",
    "LAB_simi_w_dict_collection = {\n",
    "    \"Euc\": {\"score\": LAB_Euc_simi_w_train_clean, \"label\":LAB_Euc_y_w_train_clean},\n",
    "    \"Cos\": {\"score\": LAB_Cos_simi_w_train_clean, \"label\":LAB_Cos_y_w_train_clean},\n",
    "    \"Manh\": {\"score\": LAB_Manh_simi_w_train_clean, \"label\":LAB_Manh_y_w_train_clean},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b37150-7dfd-46b8-bd7d-a0863712cc63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LAB no overlap weighting no weighted voting\n",
    "# vv is vanilla voting\n",
    "# no is not overlap weighting\n",
    "LAB_no_vv = compare_feature_repr(LAB_simi_dict_collection, y_train, k_sizes, use_weighted_voting = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142a4a36-085b-4bed-bda5-872fa938eb71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LAB yes overlap weighting no weighted voting\n",
    "# w is overlap weighting\n",
    "LAB_ow_vv = compare_feature_repr(LAB_simi_w_dict_collection, y_train, k_sizes, use_weighted_voting = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a760bf-1493-48f2-98fe-fa91b68bc34e",
   "metadata": {},
   "source": [
    "# Add to Grid Search Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9ce324",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_search_table.loc[:, \"SCR Vanilla\"] = SCR_no_vv[\"name\"]\n",
    "grid_search_table.loc[:, \"SCR OW\"] = SCR_ow_vv[\"name\"]\n",
    "grid_search_table.loc[:, \"LAB Vanilla\"] = LAB_no_vv[\"name\"]\n",
    "grid_search_table.loc[:, \"LAB OW\"] = LAB_ow_vv[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f396b9-7e16-45a7-a3cb-ac3d5fce6f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_search_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a655ed78-15a5-46ed-bc87-12e573f9f226",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To facilitate computing, we do not use the idea of unique distance measure for each k\n",
    "# instead one metric for one condition. We use the metric that previal in the column\n",
    "best_method_each_condition = dict()\n",
    "for column in grid_search_table.columns:\n",
    "    mode_value = grid_search_table[column].mode()[0]\n",
    "    best_method_each_condition[column] = mode_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f17bc4-20e9-4d49-a85c-a16fec56718a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store best_method_each_condition\n",
    "best_method_each_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf1745c-e748-4782-8345-bff3a001f295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_best_method_each_condition(best_method_each_condition, use_overlap_weighting):\n",
    "    if not use_overlap_weighting:\n",
    "        return best_method_each_condition[\"SCR Vanilla\"], best_method_each_condition[\"LAB Vanilla\"]\n",
    "    if use_overlap_weighting:\n",
    "        return best_method_each_condition[\"SCR OW\"], best_method_each_condition[\"LAB OW\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3343d3c",
   "metadata": {},
   "source": [
    "# Test the Search Resutls On Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41380d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here since query_grid_search_table give us 2 best method (SCR + LAB) at the same time,\n",
    "# we test SCR and LAB under one condition at the same time\n",
    "def test_on_test_data(SCR_simi_dict_collection_train, LAB_simi_dict_collection_train, \n",
    "                      y_test, k_sizes, best_method_each_condition, \n",
    "                      use_overlap_weighting = False, use_weighted_voting = False):\n",
    "    \n",
    "    SCR_performance = dict()\n",
    "    SCR_performance[\"AUPRC\"] = []\n",
    "    SCR_performance[\"AUROC\"] = []\n",
    "    SCR_performance[\"F1\"] = []\n",
    "    LAB_performance = dict()\n",
    "    LAB_performance[\"AUPRC\"] = []\n",
    "    LAB_performance[\"AUROC\"] = []\n",
    "    LAB_performance[\"F1\"] = []\n",
    "    \n",
    "    best_SCR_met, best_LAB_met = get_best_method_each_condition(best_method_each_condition, use_overlap_weighting)\n",
    "    \n",
    "    \n",
    "    for k in tqdm(k_sizes):\n",
    "        \n",
    "        SCR_simi_dict = SCR_simi_dict_collection_train[best_SCR_met]\n",
    "        LAB_simi_dict = LAB_simi_dict_collection_train[best_LAB_met]\n",
    "        \n",
    "        SCR_AUPRC, SCR_AUROC, SCR_f1 = KNN(SCR_simi_dict, k, y_test, use_weighted_voting)\n",
    "        LAB_AUPRC, LAB_AUROC, LAB_f1 = KNN(LAB_simi_dict, k, y_test, use_weighted_voting)\n",
    "        \n",
    "        SCR_performance[\"AUPRC\"].append(SCR_AUPRC)\n",
    "        SCR_performance[\"AUROC\"].append(SCR_AUROC)\n",
    "        SCR_performance[\"F1\"].append(SCR_f1)\n",
    "        LAB_performance[\"AUPRC\"].append(LAB_AUPRC)\n",
    "        LAB_performance[\"AUROC\"].append(LAB_AUROC)\n",
    "        LAB_performance[\"F1\"].append(LAB_f1)\n",
    "        \n",
    "    return SCR_performance, LAB_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa179ca-5305-408c-be26-7a478319f8de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_similarity_arr_for_test(train_idx, test_idx, simi_mtx, idx_mtx, y):\n",
    "    assert(len(y) == len(train_idx) + len(test_idx))\n",
    "    neighbor_idx = remove_train_rows_and_test_columns(idx_mtx, train_idx, test_idx)\n",
    "    \n",
    "    y_arr = np.tile(y, (neighbor_idx.shape[0], 1))\n",
    "    simi_mtx_test = simi_mtx[test_idx, :]\n",
    "    \n",
    "    neighbor_simi = extract_elements_based_on_indices(neighbor_idx, simi_mtx_test)\n",
    "    neighbor_y = extract_elements_based_on_indices(neighbor_idx, y_arr)\n",
    "    return neighbor_simi, neighbor_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef2300e-9921-46fd-8a46-f88299b6ed0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_train_rows_and_test_columns(matrix, train_indices, test_indices):\n",
    "    \n",
    "    matrix = matrix[test_indices, :]\n",
    "    \n",
    "    elements_to_remove = np.array(test_indices)\n",
    "\n",
    "    # Use a list to collect the filtered rows\n",
    "    filtered_matrix = []\n",
    "\n",
    "    # Iterate over each row in the matrix\n",
    "    for row in matrix:\n",
    "        # Use boolean indexing to filter out the elements in elements_to_remove\n",
    "        filtered_row = row[~np.isin(row, elements_to_remove)]\n",
    "        filtered_matrix.append(filtered_row)\n",
    "\n",
    "    # Convert the list of filtered rows back to a NumPy array or a list of lists\n",
    "    filtered_matrix = np.array(filtered_matrix)\n",
    "\n",
    "    \n",
    "    assert(filtered_matrix.shape[0] == len(test_indices))\n",
    "    assert(filtered_matrix.shape[1] == len(train_indices))\n",
    "    \n",
    "    return filtered_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f8c7e-ddb1-4777-8db4-b39620ec3a5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_idx = list(data_train.index)\n",
    "test_idx = list(data_test.index)\n",
    "y = list(dataset['AKI_LABEL'])\n",
    "y_test = list(data_test['AKI_LABEL'])\n",
    "assert(len(train_idx) + len(test_idx) == len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced18eed-5e69-480b-a5a1-9a0a98ec74c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here _eva stands for test on test set, require the entire dataset\n",
    "SCR_DTW_simi_eva_clean, SCR_DTW_y_eva_clean = process_similarity_arr_for_test(train_idx, test_idx, SCR_DTW_simi, SCR_DTW_idx, y)\n",
    "SCR_DTW_simi_w_eva_clean, SCR_DTW_y_w_eva_clean = process_similarity_arr_for_test(train_idx, test_idx, SCR_DTW_simi_w, SCR_DTW_idx_w, y)\n",
    "\n",
    "SCR_Euc_simi_eva_clean, SCR_Euc_y_eva_clean = process_similarity_arr_for_test(train_idx, test_idx, SCR_Euc_simi, SCR_Euc_idx, y)\n",
    "SCR_Euc_simi_w_eva_clean, SCR_Euc_y_w_eva_clean = process_similarity_arr_for_test(train_idx, test_idx, SCR_Euc_simi_w, SCR_Euc_idx_w, y)\n",
    "\n",
    "SCR_Cos_simi_eva_clean, SCR_Cos_y_eva_clean = process_similarity_arr_for_test(train_idx, test_idx, SCR_Cos_simi, SCR_Cos_idx, y)\n",
    "SCR_Cos_simi_w_eva_clean, SCR_Cos_y_w_eva_clean = process_similarity_arr_for_test(train_idx, test_idx, SCR_Cos_simi_w, SCR_Cos_idx_w, y)\n",
    "\n",
    "SCR_Manh_simi_eva_clean, SCR_Manh_y_eva_clean = process_similarity_arr_for_test(train_idx, test_idx, SCR_Manh_simi, SCR_Manh_idx, y)\n",
    "SCR_Manh_simi_w_eva_clean, SCR_Manh_y_w_eva_clean = process_similarity_arr_for_test(train_idx, test_idx, SCR_Manh_simi_w, SCR_Manh_idx_w, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28fc116-be27-41ef-a45d-21a6d2866009",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here _eva stands for test on test set, require the entire dataset\n",
    "LAB_Euc_simi_eva_clean, LAB_Euc_y_eva_clean = process_similarity_arr_for_test(train_idx, test_idx, LAB_Euc_simi, LAB_Euc_idx, y)\n",
    "LAB_Euc_simi_w_eva_clean, LAB_Euc_y_w_eva_clean = process_similarity_arr_for_test(train_idx, test_idx, LAB_Euc_simi_w, LAB_Euc_idx_w, y)\n",
    "\n",
    "LAB_Cos_simi_eva_clean, LAB_Cos_y_eva_clean = process_similarity_arr_for_test(train_idx, test_idx, LAB_Cos_simi, LAB_Cos_idx, y)\n",
    "LAB_Cos_simi_w_eva_clean, LAB_Cos_y_w_eva_clean = process_similarity_arr_for_test(train_idx, test_idx, LAB_Cos_simi_w, LAB_Cos_idx_w, y)\n",
    "\n",
    "LAB_Manh_simi_eva_clean, LAB_Manh_y_eva_clean = process_similarity_arr_for_test(train_idx, test_idx, LAB_Manh_simi, LAB_Manh_idx, y)\n",
    "LAB_Manh_simi_w_eva_clean, LAB_Manh_y_w_eva_clean = process_similarity_arr_for_test(train_idx, test_idx, LAB_Manh_simi_w, LAB_Manh_idx_w, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3329b818",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_simi_dict_collection_eva = {\n",
    "    \"DTW\": {\"score\": SCR_DTW_simi_eva_clean, \"label\":SCR_DTW_y_eva_clean},\n",
    "    \"Euc\": {\"score\": SCR_Euc_simi_eva_clean, \"label\":SCR_Euc_y_eva_clean},\n",
    "    \"Cos\": {\"score\": SCR_Cos_simi_eva_clean, \"label\":SCR_Cos_y_eva_clean},\n",
    "    \"Manh\": {\"score\": SCR_Manh_simi_eva_clean, \"label\":SCR_Manh_y_eva_clean},\n",
    "}\n",
    "\n",
    "# dict of dicts of overlap rate weighted similarity\n",
    "SCR_simi_w_dict_collection_eva = {\n",
    "    \"DTW\": {\"score\": SCR_DTW_simi_w_eva_clean, \"label\":SCR_DTW_y_w_eva_clean},\n",
    "    \"Euc\": {\"score\": SCR_Euc_simi_w_eva_clean, \"label\":SCR_Euc_y_w_eva_clean},\n",
    "    \"Cos\": {\"score\": SCR_Cos_simi_w_eva_clean, \"label\":SCR_Cos_y_w_eva_clean},\n",
    "    \"Manh\": {\"score\": SCR_Manh_simi_w_eva_clean, \"label\":SCR_Manh_y_w_eva_clean},\n",
    "}\n",
    "\n",
    "LAB_simi_dict_collection_eva = {\n",
    "    \"Euc\": {\"score\": LAB_Euc_simi_eva_clean, \"label\":LAB_Euc_y_eva_clean},\n",
    "    \"Cos\": {\"score\": LAB_Cos_simi_eva_clean, \"label\":LAB_Cos_y_eva_clean},\n",
    "    \"Manh\": {\"score\": LAB_Manh_simi_eva_clean, \"label\":LAB_Manh_y_eva_clean},\n",
    "}\n",
    "\n",
    "# dict of dicts of overlap rate weighted similarity\n",
    "LAB_simi_w_dict_collection_eva = {\n",
    "    \"Euc\": {\"score\": LAB_Euc_simi_w_eva_clean, \"label\":LAB_Euc_y_w_eva_clean},\n",
    "    \"Cos\": {\"score\": LAB_Cos_simi_w_eva_clean, \"label\":LAB_Cos_y_w_eva_clean},\n",
    "    \"Manh\": {\"score\": LAB_Manh_simi_w_eva_clean, \"label\":LAB_Manh_y_w_eva_clean},\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d7b37a-ebf7-461f-bdf6-200affb6594c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here we test grid-searched measures against all other base measures under 4 conditions\n",
    "def evaluate_base_measure_on_test(SCR_base_measure, LAB_base_measure, best_method_each_condition, y_test, k_sizes,\n",
    "                                 SCR_simi_dict_collection_eva, SCR_simi_w_dict_collection_eva,\n",
    "                                  LAB_simi_dict_collection_eva, LAB_simi_w_dict_collection_eva):\n",
    "    # fill in testing base measure\n",
    "    best_method_each_condition_control = best_method_each_condition.copy()\n",
    "    for condition_name in best_method_each_condition_control.keys():\n",
    "        if condition_name.startswith(\"SCR\"):\n",
    "            best_method_each_condition_control[condition_name] = SCR_base_measure\n",
    "        elif condition_name.startswith(\"LAB\"):\n",
    "            best_method_each_condition_control[condition_name] = LAB_base_measure\n",
    "            \n",
    "    SCR_control_performance = dict()\n",
    "    LAB_control_performance = dict()\n",
    "            \n",
    "    # test under 4 conditions\n",
    "    SCR_no_vv_eva_control, LAB_no_vv_eva_control = test_on_test_data(SCR_simi_dict_collection_eva, \n",
    "                                                     LAB_simi_dict_collection_eva, \n",
    "                                                     y_test, k_sizes, best_method_each_condition_control, \n",
    "                                                     use_overlap_weighting = False, \n",
    "                                                     use_weighted_voting = False)\n",
    "    \n",
    "    SCR_no_wv_eva_control, LAB_no_wv_eva_control = test_on_test_data(SCR_simi_dict_collection_eva, \n",
    "                                                     LAB_simi_dict_collection_eva, \n",
    "                                                     y_test, k_sizes, best_method_each_condition_control, \n",
    "                                                     use_overlap_weighting = False, \n",
    "                                                     use_weighted_voting = True)\n",
    "    \n",
    "    SCR_ow_vv_eva_control, LAB_ow_vv_eva_control = test_on_test_data(SCR_simi_w_dict_collection_eva, \n",
    "                                                     LAB_simi_w_dict_collection_eva, \n",
    "                                                     y_test, k_sizes, best_method_each_condition_control, \n",
    "                                                     use_overlap_weighting = True, \n",
    "                                                     use_weighted_voting = False)\n",
    "    \n",
    "    SCR_ow_wv_eva_control, LAB_ow_wv_eva_control = test_on_test_data(SCR_simi_w_dict_collection_eva, \n",
    "                                                     LAB_simi_w_dict_collection_eva, \n",
    "                                                     y_test, k_sizes, best_method_each_condition_control, \n",
    "                                                     use_overlap_weighting = True, \n",
    "                                                     use_weighted_voting = True)\n",
    "    \n",
    "    SCR_control_performance[\"Vanilla\"] = SCR_no_vv_eva_control\n",
    "    SCR_control_performance[\"OW\"] = SCR_ow_vv_eva_control\n",
    "    SCR_control_performance[\"WV\"] = SCR_no_wv_eva_control\n",
    "    SCR_control_performance[\"OW+WV\"] = SCR_ow_wv_eva_control\n",
    "    \n",
    "    LAB_control_performance[\"Vanilla\"] = LAB_no_vv_eva_control\n",
    "    LAB_control_performance[\"OW\"] = LAB_ow_vv_eva_control\n",
    "    LAB_control_performance[\"WV\"] = LAB_no_wv_eva_control\n",
    "    LAB_control_performance[\"OW+WV\"] = LAB_ow_wv_eva_control\n",
    "    \n",
    "    return SCR_control_performance, LAB_control_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54afb17f-85f3-426d-b9fd-0820470cc8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCR_DTW_control, _ = evaluate_base_measure_on_test(\"DTW\", \"Euc\", best_method_each_condition, y_test, k_sizes,\n",
    "                                                   SCR_simi_dict_collection_eva, SCR_simi_w_dict_collection_eva,\n",
    "                                                   LAB_simi_dict_collection_eva, LAB_simi_w_dict_collection_eva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d12b166-1ab6-42a8-a527-a622caca9064",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Results_dict/Imputation_2/SCR_DTW_control.json', 'w') as file:\n",
    "    json.dump(SCR_DTW_control, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a5bbd8-feac-4b4f-a753-a5fb6a08c341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Euc_control, LAB_Euc_control = evaluate_base_measure_on_test(\"Euc\", \"Euc\", best_method_each_condition, y_test, k_sizes,\n",
    "                                                                 SCR_simi_dict_collection_eva, SCR_simi_w_dict_collection_eva, \n",
    "                                                                 LAB_simi_dict_collection_eva, LAB_simi_w_dict_collection_eva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef6e0a2-977c-4519-8f93-2cfdca594cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Results_dict/Imputation_2/SCR_Euc_control.json', 'w') as file:\n",
    "    json.dump(SCR_Euc_control, file)\n",
    "with open('./Results_dict/Imputation_2/LAB_Euc_control.json', 'w') as file:\n",
    "    json.dump(LAB_Euc_control, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc840c1f-3832-4cb4-bdea-f06a31447732",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Manh_control, LAB_Manh_control = evaluate_base_measure_on_test(\"Manh\", \"Manh\", best_method_each_condition, y_test, k_sizes,\n",
    "                                                                    SCR_simi_dict_collection_eva, SCR_simi_w_dict_collection_eva,\n",
    "                                                                    LAB_simi_dict_collection_eva, LAB_simi_w_dict_collection_eva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcb48fb-4949-4002-9a44-91262fa02672",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Results_dict/Imputation_2/SCR_Manh_control.json', 'w') as file:\n",
    "    json.dump(SCR_Manh_control, file)\n",
    "with open('./Results_dict/Imputation_2/LAB_Manh_control.json', 'w') as file:\n",
    "    json.dump(LAB_Manh_control, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7518492-81fc-4e9a-9a77-be45260c8583",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Cos_control, LAB_Cos_control = evaluate_base_measure_on_test(\"Cos\", \"Cos\", best_method_each_condition, y_test, k_sizes,\n",
    "                                                                SCR_simi_dict_collection_eva, SCR_simi_w_dict_collection_eva,\n",
    "                                                                 LAB_simi_dict_collection_eva, LAB_simi_w_dict_collection_eva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7847db3-008c-4ac4-9901-92f9d90632f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Results_dict/Imputation_2/SCR_Cos_control.json', 'w') as file:\n",
    "    json.dump(SCR_Cos_control, file)\n",
    "with open('./Results_dict/Imputation_2/LAB_Cos_control.json', 'w') as file:\n",
    "    json.dump(LAB_Cos_control, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15062d84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_no_vv_eva, LAB_no_vv_eva = test_on_test_data(SCR_simi_dict_collection_eva, \n",
    "                                                     LAB_simi_dict_collection_eva, \n",
    "                                                     y_test, k_sizes, best_method_each_condition, \n",
    "                                                     use_overlap_weighting = False, \n",
    "                                                     use_weighted_voting = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289e90e7-d683-4db8-9c79-3af219706a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Results_dict/Imputation_2/SCR_no_vv_eva.json', 'w') as file:\n",
    "    json.dump(SCR_no_vv_eva, file)\n",
    "with open('./Results_dict/Imputation_2/LAB_no_vv_eva.json', 'w') as file:\n",
    "    json.dump(LAB_no_vv_eva, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55057302",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_no_wv_eva, LAB_no_wv_eva = test_on_test_data(SCR_simi_dict_collection_eva, \n",
    "                                                     LAB_simi_dict_collection_eva, \n",
    "                                                     y_test, k_sizes, best_method_each_condition, \n",
    "                                                     use_overlap_weighting = False, \n",
    "                                                     use_weighted_voting = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8740a3c9-aebf-4f28-b51d-87fac228a736",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Results_dict/Imputation_2/SCR_no_wv_eva.json', 'w') as file:\n",
    "    json.dump(SCR_no_wv_eva, file)\n",
    "with open('./Results_dict/Imputation_2/LAB_no_wv_eva.json', 'w') as file:\n",
    "    json.dump(LAB_no_wv_eva, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1e63d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_ow_vv_eva, LAB_ow_vv_eva = test_on_test_data(SCR_simi_w_dict_collection_eva, \n",
    "                                                     LAB_simi_w_dict_collection_eva, \n",
    "                                                     y_test, k_sizes, best_method_each_condition, \n",
    "                                                     use_overlap_weighting = True, \n",
    "                                                     use_weighted_voting = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fcb953-38ad-4d4a-96af-06791fee2c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Results_dict/Imputation_2/SCR_ow_vv_eva.json', 'w') as file:\n",
    "    json.dump(SCR_ow_vv_eva, file)\n",
    "with open('./Results_dict/Imputation_2/LAB_ow_vv_eva.json', 'w') as file:\n",
    "    json.dump(LAB_ow_vv_eva, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63e05ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_ow_wv_eva, LAB_ow_wv_eva = test_on_test_data(SCR_simi_w_dict_collection_eva, \n",
    "                                                     LAB_simi_w_dict_collection_eva, \n",
    "                                                     y_test, k_sizes, best_method_each_condition, \n",
    "                                                     use_overlap_weighting = True, \n",
    "                                                     use_weighted_voting = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c1ed8c-3d41-44a7-980f-b522b626cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Results_dict/Imputation_2/SCR_ow_wv_eva.json', 'w') as file:\n",
    "    json.dump(SCR_ow_wv_eva, file)\n",
    "with open('./Results_dict/Imputation_2/LAB_ow_wv_eva.json', 'w') as file:\n",
    "    json.dump(LAB_ow_wv_eva, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5eded4-51fc-4052-8f78-e13eb8baf8e9",
   "metadata": {},
   "source": [
    "# Proof: OW and WV can Improve Performance among Base Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0c742f-db81-445a-9a33-a028be03eb13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_AUPRC_along_k(ax, k_sizes, data_no_vv, data_no_wv, data_ow_vv, data_ow_wv, title):\n",
    "    ax.plot(k_sizes, data_no_vv, label=\"Vanilla\", marker='.', markersize=7)\n",
    "    ax.plot(k_sizes, data_no_wv, label=\"Weighted Voting\", marker='.', markersize=7)\n",
    "    ax.plot(k_sizes, data_ow_vv, label=\"Overlap Weighted\", marker='.', markersize=7)\n",
    "    ax.plot(k_sizes, data_ow_wv, label=\"Overlap Weighted + Weighted Voting\", marker='.', markersize=7)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"k\")\n",
    "    ax.set_ylabel(\"AUPRC\")\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba1cecd-1e88-4c35-9e2c-a3bab6451ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10)) \n",
    "\n",
    "metric = \"AUPRC\"\n",
    "\n",
    "plot_AUPRC_along_k(axs[0,0], \n",
    "                   k_sizes,\n",
    "                   SCR_DTW_control[\"Vanilla\"][metric], \n",
    "                   SCR_DTW_control[\"WV\"][metric], \n",
    "                   SCR_DTW_control[\"OW\"][metric], \n",
    "                   SCR_DTW_control[\"OW+WV\"][metric], \n",
    "                   \"SCR: DTW as Base Model\")\n",
    "\n",
    "plot_AUPRC_along_k(axs[0,1], \n",
    "                   k_sizes,\n",
    "                   SCR_Euc_control[\"Vanilla\"][metric], \n",
    "                   SCR_Euc_control[\"WV\"][metric], \n",
    "                   SCR_Euc_control[\"OW\"][metric], \n",
    "                   SCR_Euc_control[\"OW+WV\"][metric], \n",
    "                   \"SCR: Euclidean as Base Model\")\n",
    "plot_AUPRC_along_k(axs[1,0], \n",
    "                   k_sizes,\n",
    "                   SCR_Cos_control[\"Vanilla\"][metric], \n",
    "                   SCR_Cos_control[\"WV\"][metric], \n",
    "                   SCR_Cos_control[\"OW\"][metric], \n",
    "                   SCR_Cos_control[\"OW+WV\"][metric], \n",
    "                   \"SCR: Cosine as Base Model\")\n",
    "plot_AUPRC_along_k(axs[1,1], \n",
    "                   k_sizes,\n",
    "                   SCR_Manh_control[\"Vanilla\"][metric], \n",
    "                   SCR_Manh_control[\"WV\"][metric], \n",
    "                   SCR_Manh_control[\"OW\"][metric], \n",
    "                   SCR_Manh_control[\"OW+WV\"][metric], \n",
    "                   \"SCR: Manhattan as Base Model\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b66ce3-ed56-4a04-9666-c03f700d1b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(18, 4)) \n",
    "\n",
    "metric = \"AUPRC\"\n",
    "\n",
    "plot_AUPRC_along_k(axs[0], \n",
    "                   k_sizes,\n",
    "                   LAB_Euc_control[\"Vanilla\"][metric], \n",
    "                   LAB_Euc_control[\"WV\"][metric], \n",
    "                   LAB_Euc_control[\"OW\"][metric], \n",
    "                   LAB_Euc_control[\"OW+WV\"][metric], \n",
    "                   \"LAB: Euclidean as Base Model\")\n",
    "plot_AUPRC_along_k(axs[1], \n",
    "                   k_sizes,\n",
    "                   LAB_Cos_control[\"Vanilla\"][metric], \n",
    "                   LAB_Cos_control[\"WV\"][metric], \n",
    "                   LAB_Cos_control[\"OW\"][metric], \n",
    "                   LAB_Cos_control[\"OW+WV\"][metric], \n",
    "                   \"LAB: Cosine as Base Model\")\n",
    "plot_AUPRC_along_k(axs[2], \n",
    "                   k_sizes,\n",
    "                   LAB_Manh_control[\"Vanilla\"][metric], \n",
    "                   LAB_Manh_control[\"WV\"][metric], \n",
    "                   LAB_Manh_control[\"OW\"][metric], \n",
    "                   LAB_Manh_control[\"OW+WV\"][metric], \n",
    "                   \"LAB: Manhattan as Base Model\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125a55aa-3412-4ed9-8b83-bddd027976fc",
   "metadata": {},
   "source": [
    "# Proof: Searched Measure is Better Than Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b894f50e-6650-402c-bf60-fd4578028994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_control_measure_names = [\"DTW\", \"Euc\", \"Manh\", \"Cos\"]\n",
    "\n",
    "SCR_no_vv_eva_controls = [SCR_DTW_control[\"Vanilla\"][\"AUPRC\"], SCR_Euc_control[\"Vanilla\"][\"AUPRC\"],\n",
    "                         SCR_Manh_control[\"Vanilla\"][\"AUPRC\"], SCR_Cos_control[\"Vanilla\"][\"AUPRC\"]]\n",
    "SCR_no_wv_eva_controls = [SCR_DTW_control[\"WV\"][\"AUPRC\"], SCR_Euc_control[\"WV\"][\"AUPRC\"],\n",
    "                         SCR_Manh_control[\"WV\"][\"AUPRC\"], SCR_Cos_control[\"WV\"][\"AUPRC\"]]\n",
    "SCR_ow_vv_eva_controls = [SCR_DTW_control[\"OW\"][\"AUPRC\"], SCR_Euc_control[\"OW\"][\"AUPRC\"],\n",
    "                         SCR_Manh_control[\"OW\"][\"AUPRC\"], SCR_Cos_control[\"OW\"][\"AUPRC\"]]\n",
    "SCR_ow_wv_eva_controls = [SCR_DTW_control[\"OW+WV\"][\"AUPRC\"], SCR_Euc_control[\"OW+WV\"][\"AUPRC\"],\n",
    "                         SCR_Manh_control[\"OW+WV\"][\"AUPRC\"], SCR_Cos_control[\"OW+WV\"][\"AUPRC\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e70f63b-5e9c-4c94-8c88-7f3b8f8ce120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_control_vs_exp_performance(ax, k_sizes, feature_eva_controls, control_measure_names, best_measure_name, title):\n",
    "    markersize = 7\n",
    "    \n",
    "    best_idx = control_measure_names.index(best_measure_name)\n",
    "    \n",
    "    candidate_control_linecolor = ['deepskyblue', 'dodgerblue', 'skyblue', 'steelblue', \n",
    "                                   'cornflowerblue', 'royalblue', 'mediumblue', 'slateblue', 'darkblue']\n",
    "    for i in range(len(control_measure_names)):\n",
    "        if i == best_idx:\n",
    "            color = \"red\"\n",
    "            alpha = 1.0\n",
    "        else:\n",
    "            color = candidate_control_linecolor[i]\n",
    "            alpha = 0.3\n",
    "        ax.plot(k_sizes, feature_eva_controls[i], label=\"Control - %s\"%(control_measure_names[i]), \n",
    "                marker='.', markersize=markersize, color = color, alpha = alpha)\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('k')\n",
    "    ax.set_ylabel('AUPRC')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fdc110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))  # 2x2 grid of subplots, adjust the figure size as needed\n",
    "\n",
    "plot_control_vs_exp_performance(axs[0, 0], k_sizes, SCR_no_vv_eva_controls, SCR_control_measure_names, \n",
    "                                best_method_each_condition[\"SCR Vanilla\"], 'SCR of Test Set: Vanilla Performance')\n",
    "plot_control_vs_exp_performance(axs[0, 1], k_sizes, SCR_no_wv_eva_controls, SCR_control_measure_names, \n",
    "                                best_method_each_condition[\"SCR Vanilla\"],'SCR of Test Set: Weighted Voting Performance')\n",
    "plot_control_vs_exp_performance(axs[1, 0], k_sizes, SCR_ow_vv_eva_controls, SCR_control_measure_names, \n",
    "                                best_method_each_condition[\"SCR OW\"],'SCR of Test Set: Overlap Weighted Performance')\n",
    "plot_control_vs_exp_performance(axs[1, 1], k_sizes, SCR_ow_wv_eva_controls, SCR_control_measure_names, \n",
    "                                best_method_each_condition[\"SCR OW\"],'SCR of Test Set: Overlap Weighted + Weighted Voting Performance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dc23a1-7617-423a-b2bd-995737a175bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_sizes, SCR_no_vv_eva[\"AUPRC\"], label = \"Vanilla\", marker='.', markersize=7)\n",
    "plt.plot(k_sizes, SCR_no_wv_eva[\"AUPRC\"], label = \"Wighted Voting\", marker='.', markersize=7)\n",
    "plt.plot(k_sizes, SCR_ow_vv_eva[\"AUPRC\"], label = \"Overlap Weighted\", marker='.', markersize=7)\n",
    "plt.plot(k_sizes, SCR_ow_wv_eva[\"AUPRC\"], label = \"Overlap Weighted + Weighted Voting\", marker='.', markersize=7)\n",
    "plt.title(\"SCR: Search for Best Distance Metric under 4 Conditions\")\n",
    "plt.ylabel('AUPRC')\n",
    "plt.xlabel('k')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e421b60f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LAB_control_measure_names = [\"Euc\", \"Manh\", \"Cos\"]\n",
    "LAB_no_vv_eva_controls = [LAB_Euc_control[\"Vanilla\"][\"AUPRC\"], LAB_Manh_control[\"Vanilla\"][\"AUPRC\"], LAB_Cos_control[\"Vanilla\"][\"AUPRC\"]]\n",
    "LAB_no_wv_eva_controls = [LAB_Euc_control[\"WV\"][\"AUPRC\"], LAB_Manh_control[\"WV\"][\"AUPRC\"], LAB_Cos_control[\"WV\"][\"AUPRC\"]]\n",
    "LAB_ow_vv_eva_controls = [LAB_Euc_control[\"OW\"][\"AUPRC\"], LAB_Manh_control[\"OW\"][\"AUPRC\"], LAB_Cos_control[\"OW\"][\"AUPRC\"]]\n",
    "LAB_ow_wv_eva_controls = [LAB_Euc_control[\"OW+WV\"][\"AUPRC\"], LAB_Manh_control[\"OW+WV\"][\"AUPRC\"], LAB_Cos_control[\"OW+WV\"][\"AUPRC\"]]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))  # 2x2 grid of subplots, adjust the figure size as needed\n",
    "\n",
    "plot_control_vs_exp_performance(axs[0, 0], k_sizes, LAB_no_vv_eva_controls, LAB_control_measure_names, \n",
    "                                best_method_each_condition[\"LAB Vanilla\"], 'LAB of Test Set: Vanilla Performance')\n",
    "plot_control_vs_exp_performance(axs[0, 1], k_sizes, LAB_no_wv_eva_controls, LAB_control_measure_names, \n",
    "                                best_method_each_condition[\"LAB Vanilla\"], 'LAB of Test Set: Weighted Voting Performance')\n",
    "plot_control_vs_exp_performance(axs[1, 0], k_sizes, LAB_ow_vv_eva_controls, LAB_control_measure_names, \n",
    "                                best_method_each_condition[\"LAB OW\"], 'LAB of Test Set: Overlap Weighted Performance')\n",
    "plot_control_vs_exp_performance(axs[1, 1], k_sizes, LAB_ow_wv_eva_controls, LAB_control_measure_names, \n",
    "                                best_method_each_condition[\"LAB OW\"], 'LAB of Test Set: Overlap Weighted + Weighted Voting Performance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d359794b-bd51-472a-a9c5-db5f6373eea0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_sizes, LAB_no_vv_eva[\"AUPRC\"], label = \"Vanilla\", marker='.', markersize=7)\n",
    "plt.plot(k_sizes, LAB_no_wv_eva[\"AUPRC\"], label = \"Wighted Voting\", marker='.', markersize=7)\n",
    "plt.plot(k_sizes, LAB_ow_vv_eva[\"AUPRC\"], label = \"Overlap Weighted\", marker='.', markersize=7)\n",
    "plt.plot(k_sizes, LAB_ow_wv_eva[\"AUPRC\"], label = \"Overlap Weighted + Wighted Voting\", marker='.', markersize=7)\n",
    "plt.title(\"LAB: Search for Best Distance Metric under 4 Conditions\")\n",
    "plt.ylabel('AUPRC')\n",
    "plt.xlabel('k')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ada293",
   "metadata": {},
   "source": [
    "# Search Weights to Combine Feature Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4bfc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c39faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all simi mtx for reference\n",
    "# _w is for overlap weighting\n",
    "# we cannot transform them into dict now because they need to be weighted sumed\n",
    "# then they will be transformed into simi idx and then dict\n",
    "all_simi_mtx_collection_train = dict()\n",
    "\n",
    "all_simi_mtx_collection_train[\"SCR\"] = dict()\n",
    "all_simi_mtx_collection_train[\"LAB\"] = dict()\n",
    "\n",
    "all_simi_mtx_collection_train[\"SCR\"][\"DTW\"] = SCR_DTW_simi_train\n",
    "all_simi_mtx_collection_train[\"SCR\"][\"Euc\"] = SCR_Euc_simi_train\n",
    "all_simi_mtx_collection_train[\"SCR\"][\"Cos\"] = SCR_Cos_simi_train\n",
    "all_simi_mtx_collection_train[\"SCR\"][\"Manh\"] = SCR_Manh_simi_train\n",
    "\n",
    "all_simi_mtx_collection_train[\"LAB\"][\"Euc\"] = LAB_Euc_simi_train\n",
    "all_simi_mtx_collection_train[\"LAB\"][\"Manh\"] = LAB_Manh_simi_train\n",
    "all_simi_mtx_collection_train[\"LAB\"][\"Cos\"] = LAB_Cos_simi_train\n",
    "\n",
    "all_simi_w_mtx_collection_train = dict()\n",
    "\n",
    "all_simi_w_mtx_collection_train[\"SCR\"] = dict()\n",
    "all_simi_w_mtx_collection_train[\"LAB\"] = dict()\n",
    "\n",
    "all_simi_w_mtx_collection_train[\"SCR\"][\"DTW\"] = SCR_DTW_simi_w_train\n",
    "all_simi_w_mtx_collection_train[\"SCR\"][\"Euc\"] = SCR_Euc_simi_w_train\n",
    "all_simi_w_mtx_collection_train[\"SCR\"][\"Cos\"] = SCR_Cos_simi_w_train\n",
    "all_simi_w_mtx_collection_train[\"SCR\"][\"Manh\"] = SCR_Manh_simi_w_train\n",
    "\n",
    "all_simi_w_mtx_collection_train[\"LAB\"][\"Euc\"] = LAB_Euc_simi_w_train\n",
    "all_simi_w_mtx_collection_train[\"LAB\"][\"Manh\"] = LAB_Manh_simi_w_train\n",
    "all_simi_w_mtx_collection_train[\"LAB\"][\"Cos\"] = LAB_Cos_simi_w_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747e4ab5-7603-4daa-b674-9e8fbf84fc0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we do not need to pass all the mtx, just need the best method one\n",
    "best_measure_simi_mtx_train = dict()\n",
    "best_measure_simi_w_mtx_train = dict()\n",
    "\n",
    "best_measure_simi_mtx_train[\"SCR\"] = all_simi_mtx_collection_train[\"SCR\"][best_method_each_condition[\"SCR Vanilla\"]]\n",
    "best_measure_simi_mtx_train[\"LAB\"] = all_simi_mtx_collection_train[\"LAB\"][best_method_each_condition[\"LAB Vanilla\"]]\n",
    "\n",
    "best_measure_simi_w_mtx_train[\"SCR\"] = all_simi_w_mtx_collection_train[\"SCR\"][best_method_each_condition[\"SCR OW\"]]\n",
    "best_measure_simi_w_mtx_train[\"LAB\"] = all_simi_w_mtx_collection_train[\"LAB\"][best_method_each_condition[\"LAB OW\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ff8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all possible weight combination\n",
    "# A is for weighting SCR, B is for LAB\n",
    "weight_combos = []\n",
    "for A in np.arange(0.1, 1.1, 0.1):\n",
    "    for B in np.arange(0.1, 1.1, 0.1):\n",
    "        if A + B == 1:\n",
    "            weight_combos.append((round(A, 1), round(B, 1)))  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8522455f-e14c-4dad-9e4a-4501d5a4974b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get how many combination of parameters in total\n",
    "len(weight_combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0fe203-d8dd-4eda-836e-d2886a438a2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store weight_combos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1045a7fe",
   "metadata": {},
   "source": [
    "Weight Searching Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e33891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799e6a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_combo_weights_parallel(num_processors):\n",
    "    # Use Pool with imap_unordered and wrap with tqdm\n",
    "    with Pool(num_processors) as pool:\n",
    "        results = list(tqdm(pool.imap(process_for_single_k, k_sizes), \n",
    "                            total=len(k_sizes)))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9c74b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worker function to handle all weight combinations for a single k\n",
    "def process_for_single_k(k):\n",
    "    # Get the best feature type similarity measures for the current k\n",
    "    # Retrieve best similarity arrays\n",
    "    SCR_best_simi_train = ref_simi_mtx_collection_train[\"SCR\"]\n",
    "    LAB_best_simi_train = ref_simi_mtx_collection_train[\"LAB\"]\n",
    "    \n",
    "    assert(SCR_best_simi_train.shape[0] == LAB_best_simi_train.shape[0])\n",
    "\n",
    "    best_AUPRC = 0\n",
    "    best_AUROC = 0\n",
    "    best_weight_combo = None\n",
    "\n",
    "    # Iterate over all weight combinations\n",
    "    for (A, B) in weight_combos:\n",
    "        \n",
    "        # search is under no weighted voting KNN\n",
    "        AUPRC, _, _ = combo_weights_evaluate_for_train(SCR_best_simi_train, LAB_best_simi_train, \n",
    "                                                        A, B, train_idx, y_train, k, False)\n",
    "        if AUPRC > best_AUPRC:\n",
    "            best_AUPRC = AUPRC\n",
    "            best_weight_combo = (A, B)\n",
    "\n",
    "    return [k, best_AUPRC, best_weight_combo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6686354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combo_weights_evaluate_for_train(SCR_simi_train, LAB_simi_train, A, B, \n",
    "                           train_idx, y_train, k, use_weighted_voting):\n",
    "    # weighted sum of the simi mtxs and min-max normalization \n",
    "    combined_simi_train = A * SCR_simi_train + B * LAB_simi_train\n",
    "    combined_simi_train = min_max_normalization(combined_simi_train)\n",
    "    # get the ordered idx\n",
    "    combined_idx_train = slow_argsort(combined_simi_train)\n",
    "    # organize the sorted idx into dict\n",
    "    neighbor_simi, neighbor_y = process_similarity_arr_for_train(train_idx, y_train, \n",
    "                                                     combined_simi_train, combined_idx_train)\n",
    "    combined_dict = {\"score\": neighbor_simi, \"label\": neighbor_y}\n",
    "    \n",
    "    #trainlute the KNN results\n",
    "    AUPRC, AUROC, f1 = KNN(combined_dict, k, y_train, use_weighted_voting)\n",
    "    return AUPRC, AUROC, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a6c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no overlap weigting no weighted KNN voting\n",
    "use_overlap_weighting=False  \n",
    "ref_simi_mtx_collection_train = best_measure_simi_mtx_train\n",
    "weight_combos_vv = search_combo_weights_parallel(num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b75cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yes overlap weigting no weighted KNN voting\n",
    "use_overlap_weighting=True  \n",
    "ref_simi_mtx_collection_train = best_measure_simi_w_mtx_train\n",
    "weight_combos_w_vv = search_combo_weights_parallel(num_processors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f591f4",
   "metadata": {},
   "source": [
    "# Add Weight Combo Results to Grid Search Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de9278",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_table[\"ALL Vanilla\"] = [info[2] for info in weight_combos_vv]\n",
    "grid_search_table[\"ALL OW\"] = [info[2] for info in weight_combos_w_vv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35810017",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d76eb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_table.to_csv(\"/blue/yonghui.wu/lideyi/Personalization_Methodology/grid_search_table_imput2.csv\",\n",
    "                        index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a987cf9-79f5-4916-838e-15acdece2338",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_search_table = pd.read_csv(\"/blue/yonghui.wu/lideyi/Personalization_Methodology/grid_search_table_imput2.csv\",\n",
    "                               index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a9d223-fccf-484d-b340-0d1095e4f5b0",
   "metadata": {},
   "source": [
    "# Apply Searched Weights and Metrics to Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa61dac7-0225-487f-b82f-a22910a3abab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_simi_mtx_collection = dict()\n",
    "\n",
    "all_simi_mtx_collection[\"SCR\"] = dict()\n",
    "all_simi_mtx_collection[\"LAB\"] = dict()\n",
    "\n",
    "all_simi_mtx_collection[\"SCR\"][\"DTW\"] = SCR_DTW_simi\n",
    "all_simi_mtx_collection[\"SCR\"][\"Euc\"] = SCR_Euc_simi\n",
    "all_simi_mtx_collection[\"SCR\"][\"Cos\"] = SCR_Cos_simi\n",
    "all_simi_mtx_collection[\"SCR\"][\"Manh\"] = SCR_Manh_simi\n",
    "\n",
    "\n",
    "all_simi_mtx_collection[\"LAB\"][\"Euc\"] = LAB_Euc_simi\n",
    "all_simi_mtx_collection[\"LAB\"][\"Manh\"] = LAB_Manh_simi\n",
    "all_simi_mtx_collection[\"LAB\"][\"Cos\"] = LAB_Cos_simi\n",
    "\n",
    "all_simi_w_mtx_collection = dict()\n",
    "\n",
    "all_simi_w_mtx_collection[\"SCR\"] = dict()\n",
    "all_simi_w_mtx_collection[\"LAB\"] = dict()\n",
    "\n",
    "all_simi_w_mtx_collection[\"SCR\"][\"DTW\"] = SCR_DTW_simi_w\n",
    "all_simi_w_mtx_collection[\"SCR\"][\"Euc\"] = SCR_Euc_simi_w\n",
    "all_simi_w_mtx_collection[\"SCR\"][\"Cos\"] = SCR_Cos_simi_w\n",
    "all_simi_w_mtx_collection[\"SCR\"][\"Manh\"] = SCR_Manh_simi_w\n",
    "\n",
    "all_simi_w_mtx_collection[\"LAB\"][\"Euc\"] = LAB_Euc_simi_w\n",
    "all_simi_w_mtx_collection[\"LAB\"][\"Manh\"] = LAB_Manh_simi_w\n",
    "all_simi_w_mtx_collection[\"LAB\"][\"Cos\"] = LAB_Cos_simi_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7343efff-ceca-407e-8da4-37d2203ac889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we do not need to pass all the mtx, just need the best method one\n",
    "best_measure_simi_mtx = dict()\n",
    "best_measure_simi_w_mtx = dict()\n",
    "\n",
    "best_measure_simi_mtx[\"SCR\"] = all_simi_mtx_collection[\"SCR\"][best_method_each_condition[\"SCR Vanilla\"]]\n",
    "best_measure_simi_mtx[\"LAB\"] = all_simi_mtx_collection[\"LAB\"][best_method_each_condition[\"LAB Vanilla\"]]\n",
    "\n",
    "best_measure_simi_w_mtx[\"SCR\"] = all_simi_w_mtx_collection[\"SCR\"][best_method_each_condition[\"SCR OW\"]]\n",
    "best_measure_simi_w_mtx[\"LAB\"] = all_simi_w_mtx_collection[\"LAB\"][best_method_each_condition[\"LAB OW\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b88da0-ffc3-43b3-9e1a-8c4abab357ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_final_personalized_model(k_sizes, use_overlap_weighting, use_weighted_voting, \n",
    "                                  grid_search_table, train_idx, test_idx, y, y_test, best_measure_simi_mtx):\n",
    "    results = dict()\n",
    "    results[\"AUPRC\"] = []\n",
    "    results[\"AUROC\"] = []\n",
    "    results[\"F1\"] = []\n",
    "        \n",
    "    # get the corresponding simi mtx\n",
    "    SCR_best_simi = best_measure_simi_mtx[\"SCR\"]\n",
    "    LAB_best_simi = best_measure_simi_mtx[\"LAB\"]\n",
    "    \n",
    "    for k in tqdm(k_sizes):\n",
    "        \n",
    "        best_weight_combo = eval(query_grid_search_table_for_weights(grid_search_table, k, use_overlap_weighting))\n",
    "        \n",
    "        A = best_weight_combo[0]\n",
    "        B = best_weight_combo[1]\n",
    "        \n",
    "        combined_dict = combo_weights_evaluate_for_test(SCR_best_simi, LAB_best_simi, A, B, train_idx, test_idx, y)\n",
    "        \n",
    "        AUPRC, AUROC, f1 = KNN(combined_dict, k, y_test, use_weighted_voting)\n",
    "        \n",
    "        results[\"AUPRC\"].append(AUPRC)\n",
    "        results[\"AUROC\"].append(AUROC)\n",
    "        results[\"F1\"].append(f1)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10325314-9cc7-4839-afca-8457c6b81993",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combo_weights_evaluate_for_test(SCR_simi, LAB_simi, A, B, train_idx, test_idx, y):\n",
    "    # weighted sum of the simi mtxs and min-max normalization \n",
    "    combined_simi = A * SCR_simi + B * LAB_simi\n",
    "    combined_simi = min_max_normalization(combined_simi)\n",
    "    # get the ordered idx\n",
    "    combined_idx = slow_argsort(combined_simi)\n",
    "    # organize the sorted idx into dict\n",
    "    neighbor_simi, neighbor_y = process_similarity_arr_for_test(train_idx, test_idx, \n",
    "                                                                combined_simi, combined_idx, y)\n",
    "    combined_dict = {\"score\": neighbor_simi, \"label\": neighbor_y}\n",
    "    return combined_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8a4972-87f8-4361-a571-9723f473a5ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_grid_search_table_for_weights(grid_search_table, k, use_overlap_weighting):\n",
    "    if not use_overlap_weighting:\n",
    "        return grid_search_table.loc[k, \"ALL Vanilla\"]\n",
    "    elif use_overlap_weighting:\n",
    "        return grid_search_table.loc[k, \"ALL OW\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e97faf7-5cb4-4286-99cc-a2a3020fd1ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = np.array(dataset[\"AKI_LABEL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c882fd4-d7cd-4038-ab10-f1e8b727e5a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_performance_no_vv = test_final_personalized_model(k_sizes, False, False, \n",
    "                                                       grid_search_table,\n",
    "                                                       train_idx, test_idx, y, y_test, \n",
    "                                                       best_measure_simi_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79b1c64-094e-43aa-b376-142dea935524",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Results_dict/Imputation_2/final_performance_no_vv.json', 'w') as file:\n",
    "    json.dump(final_performance_no_vv, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0fbe24-2af8-4b8d-a659-0c3b45b2468e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_performance_no_wv = test_final_personalized_model(k_sizes, False, True, \n",
    "                                                       grid_search_table,\n",
    "                                                       train_idx, test_idx, y, y_test, \n",
    "                                                       best_measure_simi_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9385fbd4-c9f5-4681-9417-6e3f66d7f303",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Results_dict/Imputation_2/final_performance_no_wv.json', 'w') as file:\n",
    "    json.dump(final_performance_no_wv, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f800e4-d768-463d-98c9-576f20098d88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_performance_ow_vv = test_final_personalized_model(k_sizes, True, False, \n",
    "                                                        grid_search_table,\n",
    "                                                        train_idx, test_idx, y, y_test, \n",
    "                                                        best_measure_simi_w_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cec556-3fa7-4cb9-befa-3932c00847cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Results_dict/Imputation_2/final_performance_ow_vv.json', 'w') as file:\n",
    "    json.dump(final_performance_ow_vv, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d29c381-8948-43d4-8be1-b1b62725f5f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_performance_ow_wv = test_final_personalized_model(k_sizes, True, True, \n",
    "                                                       grid_search_table,\n",
    "                                                       train_idx, test_idx, y, y_test, \n",
    "                                                       best_measure_simi_w_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ef44d-b172-4584-a4a6-78aef9ddacdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Results_dict/Imputation_2/final_performance_ow_wv.json', 'w') as file:\n",
    "    json.dump(final_performance_ow_wv, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7a2cea-d592-495a-8dcc-0eb4364b6950",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_weight_control_performance(k_sizes, use_overlap_weighting, use_weighted_voting, \n",
    "                                  weight_combos, train_idx, test_idx, y, y_test, best_measure_simi_mtx):\n",
    "    results = dict()\n",
    "    \n",
    "    # get the corresponding simi mtx\n",
    "    SCR_best_simi = best_measure_simi_mtx[\"SCR\"] \n",
    "    LAB_best_simi = best_measure_simi_mtx[\"LAB\"]\n",
    "    \n",
    "    for (A, B) in tqdm(weight_combos):\n",
    "        \n",
    "        results[str((A, B))] = dict()\n",
    "        results[str((A, B))][\"AUPRC\"] = []\n",
    "        results[str((A, B))][\"AUROC\"] = []\n",
    "        results[str((A, B))][\"F1\"] = []\n",
    "        \n",
    "        combined_dict = combo_weights_evaluate_for_test(SCR_best_simi, LAB_best_simi, A, B, \n",
    "                                                        train_idx, test_idx, y) \n",
    "        for k in (k_sizes):\n",
    "            \n",
    "            AUPRC, AUROC, f1 = KNN(combined_dict, k, y_test, use_weighted_voting)\n",
    "            \n",
    "        \n",
    "            results[str((A, B))][\"AUPRC\"].append(AUPRC)\n",
    "            results[str((A, B))][\"AUROC\"].append(AUROC)\n",
    "            results[str((A, B))][\"F1\"].append(f1)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ef9487-f578-4191-b68d-1a4308f12ca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weight_control_performance_no_vv = get_weight_control_performance(k_sizes, False, False, \n",
    "                                  weight_combos, train_idx, test_idx, y, y_test, best_measure_simi_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffaa0fa-b892-4782-b557-f0c0ca45a22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Results_dict/Imputation_2/weight_control_performance_no_vv.json', 'w') as file:\n",
    "    json.dump(weight_control_performance_no_vv, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6ec127-f9bb-4fe8-8b4f-f9bb8493048c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weight_control_performance_no_wv = get_weight_control_performance(k_sizes, False, True, \n",
    "                                                       weight_combos, train_idx, test_idx, y, y_test, best_measure_simi_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c35bd9c-75e8-4112-a949-a42423192acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Results_dict/Imputation_2/weight_control_performance_no_wv.json', 'w') as file:\n",
    "    json.dump(weight_control_performance_no_wv, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5ad275-3f73-4222-8f28-2ef32a26f860",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weight_control_performance_ow_vv = get_weight_control_performance(k_sizes, True, False, \n",
    "                                                       weight_combos, train_idx, test_idx, y, y_test, best_measure_simi_w_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8c60c7-3339-4404-8a3f-33478a18bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Results_dict/Imputation_2/weight_control_performance_ow_vv.json', 'w') as file:\n",
    "    json.dump(weight_control_performance_ow_vv, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1ea629-81eb-451b-bf25-e18aa44b6823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weight_control_performance_ow_wv = get_weight_control_performance(k_sizes, True, True, \n",
    "                                                       weight_combos, train_idx, test_idx, y, y_test, best_measure_simi_w_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a12724-7f50-4f0e-9888-a84fb8ede337",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Results_dict/Imputation_2/weight_control_performance_ow_wv.json', 'w') as file:\n",
    "    json.dump(weight_control_performance_ow_wv, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55deb0d4-d47c-4c6e-8219-0d584c4ccc1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_weight_combo_control_performance(ax, k_sizes, weight_control_performance, final_performance, title):\n",
    "    \n",
    "    candidate_control_linecolor = ['lightblue', 'skyblue', 'deepskyblue', \n",
    "                                   'dodgerblue', 'cornflowerblue', 'royalblue', \n",
    "                                   'steelblue', 'mediumblue', 'darkblue', 'navy', \n",
    "                                   'midnightblue', 'slateblue', 'powderblue', 'cadetblue']\n",
    "    \n",
    "    for i, control_performance in enumerate(weight_control_performance.values()):\n",
    "        if i == 0:\n",
    "            label = \"Fixed Weights\"\n",
    "        else:\n",
    "            label = \"\"\n",
    "            \n",
    "        ax.plot(k_sizes, control_performance[\"AUPRC\"], alpha = 0.25, marker='.', \n",
    "                markersize=10, color = candidate_control_linecolor[i], label = label)\n",
    "        \n",
    "    ax.plot(k_sizes, final_performance[\"AUPRC\"], color = \"red\", alpha = 1,\n",
    "            label = \"Grid Searched Weights\", marker='.', markersize=7)\n",
    "        \n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('k')\n",
    "    ax.set_ylabel('AUPRC')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb392b3-b490-42a6-ba26-8ec213556178",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))  # 2x2 grid of subplots, adjust the figure size as needed\n",
    "\n",
    "plot_weight_combo_control_performance(axs[0, 0], k_sizes, weight_control_performance_no_vv, \n",
    "                                      final_performance_no_vv, \"Vanilla Performance\")\n",
    "plot_weight_combo_control_performance(axs[0, 1], k_sizes, weight_control_performance_no_wv, \n",
    "                                      final_performance_no_wv, \"Weighted Voting Performance\")\n",
    "plot_weight_combo_control_performance(axs[1, 0], k_sizes, weight_control_performance_ow_vv, \n",
    "                                      final_performance_ow_vv, \"Overlap Weighted Performance\")\n",
    "plot_weight_combo_control_performance(axs[1, 1], k_sizes, weight_control_performance_ow_wv, \n",
    "                                      final_performance_ow_wv, \"Overlap Weighted + Weighted Voting Performance\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d0ee14-e860-4a54-9859-0fd6e2127967",
   "metadata": {},
   "source": [
    "# Train a Global KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9f9d4a-793d-44e5-a06d-d2ab4a96c133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb2b35d-54a6-4f10-87e1-5f31df701e70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_train_ip = SCR_ip.loc[list(train_idx), :]\n",
    "SCR_test_ip = SCR_ip.loc[list(test_idx), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa0decc-2f67-4048-8489-53345d30ae98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_glob = pd.concat([SCR_train_ip, LAB_train], axis = 1)\n",
    "X_test_glob = pd.concat([SCR_test_ip, LAB_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f09ca7-ea13-4d9b-bcef-6db2142c8fbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "glob_KNN_Euc_performance = dict()\n",
    "glob_KNN_Euc_performance[\"AUPRC\"] = []\n",
    "glob_KNN_Euc_performance[\"AUROC\"] = []\n",
    "glob_KNN_Euc_performance[\"F1\"] = []\n",
    "\n",
    "for k in tqdm(k_sizes):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, p = 2)\n",
    "    knn.fit(X_train_glob, y_train)\n",
    "    y_probs = knn.predict_proba(X_test_glob)[:, 1]\n",
    "    y_preds = knn.predict(X_test_glob)\n",
    "    \n",
    "    AUPRC_glob = average_precision_score(y_test, y_probs)\n",
    "    AUROC_glob = roc_auc_score(y_test, y_probs)\n",
    "    f1_glob = f1_score(y_test, y_preds)\n",
    "    \n",
    "    glob_KNN_Euc_performance[\"AUPRC\"].append(AUPRC_glob)\n",
    "    glob_KNN_Euc_performance[\"AUROC\"].append(AUROC_glob)\n",
    "    glob_KNN_Euc_performance[\"F1\"].append(f1_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe783993-02b0-4b6f-9184-ec343773256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Results_dict/Imputation_2/glob_KNN_Euc_performance.json', 'w') as file:\n",
    "    json.dump(glob_KNN_Euc_performance, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babddcc4-d02a-4694-8282-b0558d525086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_final_performance_metrics(ax, k_sizes, metric, final_performance_no_vv, final_performance_no_wv,\n",
    "                                  final_performance_ow_vv, final_performance_ow_wv, glob_KNN_Euc_performance):\n",
    "    ax.plot(k_sizes, final_performance_no_vv[metric], label = \"Vanilla\", marker='.', markersize=7)\n",
    "    ax.plot(k_sizes, final_performance_no_wv[metric], label = \"Weighted Voting\", marker='.', markersize=7)\n",
    "    ax.plot(k_sizes, final_performance_ow_vv[metric], label = \"Overlap Weighted\", marker='.', markersize=7)\n",
    "    ax.plot(k_sizes, final_performance_ow_wv[metric], label = \"Overlap Weighted + Wighted Voting\", marker='.', markersize=7)\n",
    "    ax.plot(k_sizes, glob_KNN_Euc_performance[metric], label = \"Traditional Global KNN with Euclidean Distance\", marker='.', markersize=7)\n",
    "    ax.set_title(metric + \": All Feature Performance on Test Set\")\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_xlabel('k')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a285c16-5403-44fe-8940-3d27dadaca43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))  # 2x2 grid of subplots, adjust the figure size as needed\n",
    "\n",
    "plot_final_performance_metrics(axs[0], k_sizes, \"AUPRC\", final_performance_no_vv, final_performance_no_wv,\n",
    "                                  final_performance_ow_vv, final_performance_ow_wv, glob_KNN_Euc_performance)\n",
    "plot_final_performance_metrics(axs[1], k_sizes, \"AUROC\", final_performance_no_vv, final_performance_no_wv,\n",
    "                                  final_performance_ow_vv, final_performance_ow_wv, glob_KNN_Euc_performance)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AKI_personalized_modeling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
